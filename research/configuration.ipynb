{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'BASE_DIR' from 'attritionRate.constants' (D:\\DataScience-60\\AttritionRatePredict\\project\\attritionRate\\constants\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [89], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mattritionRate\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconstants\u001b[39;00m \u001b[39mimport\u001b[39;00m MODEL_FILE_PATH,SCHEMA_FILE_PATH,BASE_DIR,CONFIG_FILE_PATH,PARAMS_FILE_PATH,CURRENT_TIMESTAMP\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mattritionRate\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m read_yaml, create_directories\n\u001b[0;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdataclasses\u001b[39;00m \u001b[39mimport\u001b[39;00m  dataclass\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'BASE_DIR' from 'attritionRate.constants' (D:\\DataScience-60\\AttritionRatePredict\\project\\attritionRate\\constants\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from attritionRate.constants import MODEL_FILE_PATH,SCHEMA_FILE_PATH,BASE_DIR,CONFIG_FILE_PATH,PARAMS_FILE_PATH,CURRENT_TIMESTAMP\n",
    "from attritionRate.utils import read_yaml, create_directories\n",
    "from dataclasses import  dataclass\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "home = 'D:\\DataScience-60\\AttritionRatePredict'\n",
    "os.chdir(home)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "## config Entiyt\n",
    "from time import time\n",
    "from matplotlib.path import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class PipeLineConfig:\n",
    "    artifact_dir: Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataIngestionConfig:\n",
    "    source_file:str\n",
    "    dest_dir:Path\n",
    "    \n",
    "    \n",
    "@dataclass(frozen=True)\n",
    "class DataValidationConfig:\n",
    "    schema_filepath:Path\n",
    "    report_filepath:Path\n",
    "    report_page_filepath: Path\n",
    "    \n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataTransformationConfig:\n",
    "    transformed_train_dir: Path\n",
    "    transformed_test_dir: Path\n",
    "    preprocessed_obj_path: Path \n",
    "    \n",
    "    \n",
    "@dataclass(frozen=True)\n",
    "class ModelTrainingConfig:\n",
    "    model_config_filepath: Path \n",
    "    model_train_filepath: Path\n",
    "    \n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ModelEvaluationConfig:\n",
    "    model_evaluation_filepath: Path\n",
    "    time_stamp:time\n",
    "    \n",
    "    \n",
    "@dataclass(frozen=True)\n",
    "class ModelPusherConfig:\n",
    "    export_dir_path: Path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = home\n",
    "DATA_INGESTION_DIR = \"data_ingestion\"\n",
    "DATA_VALIDATION_DIR = \"data_validation\"\n",
    "DATA_TRNASFORMATION_DIR = \"data_transformation\"\n",
    "MODEL_TRAINING_DIR = \"training\"\n",
    "MODEL_EVALUATING_DIR = \"evaluation\"\n",
    "MODEL_PUSHER_DIR = \"model_export\"\n",
    "\n",
    "class Configuration:\n",
    "    def __init__(self, config_filepath=CONFIG_FILE_PATH,\n",
    "                 current_timestamp=CURRENT_TIMESTAMP):\n",
    "        self.config_info = read_yaml(config_filepath)\n",
    "        self.pipeline = self.get_training_pipeline()\n",
    "        self.timestamp = current_timestamp\n",
    "        \n",
    "    def get_data_ingestion_config(self):\n",
    "        artifacts = self.pipeline.artifact_dir\n",
    "        data_ingestion_artifact = os.path.join(artifacts, DATA_INGESTION_DIR, self.timestamp)\n",
    "        ingested_data = self.config_info.data_ingestion.destination_dir\n",
    "        \n",
    "        source_filename = self.config_info.data_ingestion.source_file\n",
    "        source_filepath = os.path.join(home, source_filename)\n",
    "        destination_dir = os.path.join(data_ingestion_artifact, ingested_data)\n",
    "        \n",
    "        data_ingestion_config = DataIngestionConfig(\n",
    "            source_file=source_filepath,\n",
    "            dest_dir=destination_dir\n",
    "        )\n",
    "        return data_ingestion_config\n",
    "        \n",
    "    def get_data_validation_config(self):\n",
    "        artifacts = self.pipeline.artifact_dir\n",
    "        validation_data = self.config_info.data_validation_config\n",
    "        validation_dir = validation_data.data_validation_dir\n",
    "        data_validation_artifact = os.path.join(artifacts, DATA_VALIDATION_DIR, self.timestamp)\n",
    "        \n",
    "        data_validation_dir = os.path.join(artifacts,validation_dir,self.timestamp)\n",
    "        \n",
    "        schema_filepath = SCHEMA_FILE_PATH\n",
    "        # report_filename': 'report.json', 'report_page_filename': 'report.html\n",
    "        report_filename = validation_data.report_filename\n",
    "        report_filepath = os.path.join(data_validation_artifact, report_filename)\n",
    "        \n",
    "        report_page_filename = validation_data.report_page_filename\n",
    "        report_page_filepath = os.path.join(data_validation_artifact, report_page_filename)\n",
    "        \n",
    "        data_validation_config = DataValidationConfig(\n",
    "            schema_filepath=schema_filepath,\n",
    "            report_filepath=report_filepath,\n",
    "            report_page_filepath=report_page_filepath\n",
    "        )\n",
    "        return data_validation_config\n",
    "\n",
    "    def get_data_transformation_config(self):\n",
    "        artifacts = self.pipeline.artifact_dir\n",
    "        # data_transformation': {'transformed_data_dir': 'transformed_data', 'transformed_train_dir': 'train', \n",
    "        # 'transformed_test_dir': 'test', 'preprocessing_dir': 'preprocessed', 'preprocessed_object_file_name': 'preprocessed.pkl'},\n",
    "        data_transformation_artifact = os.path.join(artifacts, DATA_TRNASFORMATION_DIR, self.timestamp)\n",
    "        \n",
    "        transformd_data = self.config_info.data_transformation\n",
    "        transformed_data_dir = transformd_data.transformed_data_dir\n",
    "        preprocessed_obj_dir = transformd_data.preprocessing_dir\n",
    "        \n",
    "        transformed_data_dirpath = os.path.join(data_transformation_artifact, transformed_data_dir)\n",
    "        \n",
    "        train_data_dir = transformd_data.transformed_train_dir\n",
    "        train_data_path = os.path.join(transformed_data_dirpath, train_data_dir)\n",
    "        \n",
    "        test_data_dir = transformd_data.transformed_test_dir\n",
    "        test_data_path = os.path.join(transformed_data_dirpath, test_data_dir)\n",
    "        \n",
    "        preprocessed_obj = transformd_data.preprocessing_dir\n",
    "        \n",
    "        preprocessed_obj_filename= transformd_data.preprocessed_object_file_name\n",
    "        preprocessed_obj_filepath = os.path.join(data_transformation_artifact, preprocessed_obj, preprocessed_obj_filename)\n",
    "        \n",
    "        data_transformation_config = DataTransformationConfig(\n",
    "            transformed_train_dir=train_data_path,\n",
    "            transformed_test_dir=test_data_path,\n",
    "            preprocessed_obj_path=preprocessed_obj_filepath\n",
    "        )\n",
    "        return data_transformation_config\n",
    "        \n",
    "    def get_model_training_config(self):\n",
    "        artifacts = self.pipeline.artifact_dir\n",
    "        model_config_filepath = MODEL_FILE_PATH\n",
    "        model_training_artifacts = os.path.join(artifacts, MODEL_TRAINING_DIR, self.timestamp)\n",
    "        # 'model_training': {'trained_model_dir': 'trained_model', 'trained_model_name': 'model.pkl'}\n",
    "        model_training_dir = self.config_info.model_training.trained_model_dir\n",
    "        \n",
    "        trained_model_file = os.path.join(model_training_dir, self.config_info.model_training.trained_model_name)\n",
    "        \n",
    "        model_trained_filepath = os.path.join(model_training_artifacts, trained_model_file)\n",
    "        model_training_config = ModelTrainingConfig(\n",
    "            model_config_filepath=model_config_filepath,\n",
    "            model_train_filepath=model_trained_filepath\n",
    "        )\n",
    "        return model_training_config\n",
    "        \n",
    "    def get_model_evaluation_config(self):\n",
    "        artifacts = self.pipeline.artifact_dir\n",
    "        model_evaluation_artifacts = os.path.join(artifacts, MODEL_EVALUATING_DIR, self.timestamp)\n",
    "        \n",
    "        model_evaluation = self.config_info.model_evaluating\n",
    "        # 'model_evaluating': {'evaluated_model_dir': 'model_evaluation.yaml'}\n",
    "        model_evaluating_filename = os.path.join(model_evaluation.evaluated_model_dir)\n",
    "        \n",
    "        model_evaluating_filepath = os.path.join(model_evaluation_artifacts, model_evaluating_filename)\n",
    "        model_evaluation_config = ModelEvaluationConfig(\n",
    "            model_evaluation_filepath=model_evaluating_filepath,\n",
    "            time_stamp=self.timestamp,\n",
    "        )\n",
    "        return model_evaluation_config\n",
    "        \n",
    "    def get_model_pusher_config(self):\n",
    "        artifacts = self.pipeline.artifact_dir\n",
    "        \n",
    "        timestamp = f\"{datetime.now().strftime('%Y%m%d%H%M%S')}\"\n",
    "        model_pusher_artifacts = os.path.join(home, MODEL_PUSHER_DIR, timestamp)\n",
    "        \n",
    "        model_pusher_config = ModelPusherConfig(\n",
    "            export_dir_path=model_pusher_artifacts,\n",
    "        )\n",
    "        return model_pusher_config\n",
    "        \n",
    "    def get_training_pipeline(self):\n",
    "        training_artifacts_config = self.config_info.artifacts_config\n",
    "        project = training_artifacts_config.project\n",
    "        pipeline_name = training_artifacts_config.pipeline\n",
    "        artifacts_dir = training_artifacts_config.artifacts_dir\n",
    "        \n",
    "        artifact_dir = os.path.join(ROOT_DIR,project,pipeline_name,artifacts_dir)\n",
    "        trainig_pipeline_config = PipeLineConfig(\n",
    "            artifact_dir=artifact_dir\n",
    "        )\n",
    "        return trainig_pipeline_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\DataScience-60\\AttritionRatePredict\\project\\attritionRate\\artifacts\n",
      "D:\\DataScience-60\\AttritionRatePredict\\project\\attritionRate\\artifacts\\evaluation\\2022-10-09-14-21-14\\model_evaluation.yaml\n",
      "2022-10-09-14-21-14\n",
      "D:\\DataScience-60\\AttritionRatePredict\\model_export\\20221009192158\n"
     ]
    }
   ],
   "source": [
    "config = Configuration(config_filepath=CONFIG_FILE_PATH,\n",
    "                       current_timestamp=CURRENT_TIMESTAMP)\n",
    "\n",
    "print(config.get_training_pipeline().artifact_dir)\n",
    "# print(config.get_training_pipeline())\n",
    "# print(config.get_data_ingestion_config().dest_dir)\n",
    "# print(\"file : \",config.get_data_ingestion_config().source_file)\n",
    "# print(config.get_data_validation_config().report_page_filepath)\n",
    "# filePath = config.get_data_validation_config().report_page_filepath\n",
    "# print(config.get_data_validation_config().report_filepath)\n",
    "# print(filePath)\n",
    "# print(os.path.dirname(filePath))\n",
    "# print(os.path.basename(filePath))\n",
    "# print(config.get_data_transformation_config().transformed_train_dir)\n",
    "# print(config.get_data_transformation_config().transformed_test_dir)\n",
    "# print(config.get_data_transformation_config().preprocessed_obj_path)\n",
    "# print(config.get_model_training_config().model_config_filepath)\n",
    "# print(config.get_model_training_config().model_train_filepath)\n",
    "print(config.get_model_evaluation_config().model_evaluation_filepath)\n",
    "print(config.get_model_evaluation_config().time_stamp)\n",
    "print(config.get_model_pusher_config().export_dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Oct  9 19:21:58 2022\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "print(time.asctime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'artifacts_config': {'project': 'project', 'pipeline': 'attritionRate', 'artifacts_dir': 'artifacts'}, 'data_ingestion': {'destination_dir': 'ingested_data', 'source_file': 'Table_1.csv', 'ingested_train_dir': 'train', 'ingested_test_dir': 'test', 'raw_data_dir': 'raw_data'}, 'data_validation_config': {'data_validation_dir': 'validation_data', 'schema_filename': 'schema.yaml', 'report_filename': 'report.json', 'report_page_filename': 'report.html'}, 'data_transformation': {'transformed_data_dir': 'transformed_data', 'transformed_train_dir': 'train', 'transformed_test_dir': 'test', 'preprocessing_dir': 'preprocessed', 'preprocessed_object_file_name': 'preprocessed.pkl'}, 'model_training': {'trained_model_dir': 'trained_model', 'trained_model_name': 'model.pkl'}, 'model_evaluating': {'evaluated_model_dir': 'model_evaluation.yaml'}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'artifacts'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg = read_yaml(CONFIG_FILE_PATH)\n",
    "print(cfg)\n",
    "cfg.artifacts_config.project\n",
    "cfg.artifacts_config.pipeline\n",
    "cfg.artifacts_config.artifacts_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data_validation_dir': 'validation_data', 'schema_filename': 'schema.yaml', 'report_filename': 'report.json', 'report_page_filename': 'report.html'}\n"
     ]
    }
   ],
   "source": [
    "print(cfg.data_validation_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'BASE_DIR' from 'attritionRate.constants' (D:\\DataScience-60\\AttritionRatePredict\\project\\attritionRate\\constants\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [88], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mattritionRate\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcomponents\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata_ingestion\u001b[39;00m \u001b[39mimport\u001b[39;00m DataIngestion\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mattritionRate\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mentity\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconfig_entity\u001b[39;00m \u001b[39mimport\u001b[39;00m DataIngestionConfig\n",
      "File \u001b[1;32mD:\\DataScience-60\\AttritionRatePredict\\project\\attritionRate\\components\\data_ingestion.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mattritionRate\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconfig\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconfiguration\u001b[39;00m \u001b[39mimport\u001b[39;00m Configuration\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mattritionRate\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconstants\u001b[39;00m \u001b[39mimport\u001b[39;00m CURRENT_TIMESTAMP, CONFIG_FILE_PATH, BASE_DIR\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mattritionRate\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m read_yaml, create_directories\n",
      "File \u001b[1;32mD:\\DataScience-60\\AttritionRatePredict\\project\\attritionRate\\config\\configuration.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mattritionRate\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconstants\u001b[39;00m \u001b[39mimport\u001b[39;00m (CONFIG_FILE_PATH,MODEL_FILE_PATH,BASE_DIR,\n\u001b[0;32m      2\u001b[0m                                      SCHEMA_FILE_PATH,CURRENT_TIMESTAMP)\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mattritionRate\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m read_yaml, create_directories\n\u001b[0;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mattritionRate\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mentity\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m      5\u001b[0m     DataIngestionConfig,DataValidationConfig,ModelEvaluationConfig,\n\u001b[0;32m      6\u001b[0m     ModelPusherConfig,ModelTrainingConfig,DataTransformationConfig,PipeLineConfig)\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'BASE_DIR' from 'attritionRate.constants' (D:\\DataScience-60\\AttritionRatePredict\\project\\attritionRate\\constants\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from attritionRate.components.data_ingestion import DataIngestion\n",
    "from attritionRate.entity.config_entity import DataIngestionConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d206f28065d50634c5d9a8635961150b093b5103a58da2eac4d94e260f184ed8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
